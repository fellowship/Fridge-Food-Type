{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.8/site-packages (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.8/site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./anaconda3/lib/python3.8/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.8/site-packages (from requests) (1.25.9)\n",
      "Requirement already satisfied: selenium in ./anaconda3/lib/python3.8/site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in ./anaconda3/lib/python3.8/site-packages (from selenium) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_to_end(wd, sleep_between_interactions):\n",
    "\twd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\ttime.sleep(sleep_between_interactions)\n",
    "\n",
    "# generating query\n",
    "def get_query_url(query):\n",
    "\tsearch_url = \"https://www.google.co.in/search?q={q}&source=lnms&tbm=isch\"\n",
    "\treturn  search_url.format(q = \"+\".join(query.rstrip().split()))\n",
    "\n",
    "def extractImagesURLS(query, url, total, wait_time, web_driver, verbose):\n",
    "\ttarget_url = get_query_url(query) if url is None else url\n",
    "\t# initializing the web driver\n",
    "\tweb_driver.get(target_url)\n",
    "\timage_urls = set()\n",
    "\timage_count = 0\n",
    "\tstarting_index = 0\n",
    "\tindex = 0\n",
    "\twhile image_count < N:\n",
    "\t\t# scrolling til the end to load images\n",
    "\t\tscroll_to_end(web_driver, wait_time + 0.7)\n",
    "\t\t# finding all the thumbnails images which will be opened later to download original image\n",
    "\t\tthumbnail_results = web_driver.find_elements_by_css_selector(\"img.Q4LuWd\")\n",
    "\t\tfinal_index = len(thumbnail_results)\n",
    "\t\tif final_index == starting_index:\n",
    "\t\t\tprint(f\"Can't load more images, total images found till now : {len(thumbnail_results)}\\n\\\n",
    "\t\t\t\tStopping Searching for more images\")\n",
    "\t\t\tbreak\n",
    "\t\tprint(f\"Found: {final_index} search results. Extracting links from {starting_index} : {final_index}\")\n",
    "\t\tfor img in thumbnail_results[starting_index: final_index]:\n",
    "\t\t\ttry:\n",
    "\t\t\t\t# clicking the thumbnail to get the original image\n",
    "\t\t\t\timg.click()\n",
    "\t\t\t\ttime.sleep(wait_time)\n",
    "\t\t\texcept Exception:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# scraping original image\n",
    "\t\t\tactual_images = web_driver.find_elements_by_css_selector('img.n3VNCb')\n",
    "\t\t\tfor actual_image in actual_images:\n",
    "\t\t\t\tif actual_image.get_attribute('src') and 'http' in actual_image.get_attribute('src'):\n",
    "\t\t\t\t\t# adding url to the set\n",
    "\t\t\t\t\timage_urls.add(actual_image.get_attribute('src'))\n",
    "\t\t\timage_count = len(image_urls)\n",
    "\t\t\tif len(image_urls) >= N:\n",
    "\t\t\t\tbreak\n",
    "\t\tstarting_index = final_index\n",
    "\t\tprint(f'checking for the limit of the number of images to be downloaded: {image_count}')\n",
    "\t\tif len(image_urls) >= N:\n",
    "\t\t\tprint(f\"Found: {len(image_urls)} image links\")\n",
    "\t\t\tbreak\n",
    "\t\telse :\n",
    "\t\t\tif verbose : print(f\"looking for more...\\nSo far, got links for {len(image_urls)}\")\n",
    "\t\t\t# clicking `load more button` at the end of the google image search web page to load more\n",
    "\t\t\tload_more_button = web_driver.find_element_by_css_selector(\"input.mye4qd\")\n",
    "\t\t\tif load_more_button:\n",
    "\t\t\t\tweb_driver.execute_script(\"document.querySelector('input.mye4qd').click();\")\n",
    "\tweb_driver.quit()\n",
    "\treturn image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download images from corresponding to the url\n",
    "def download_image(url, output_path, verbose):\n",
    "\ttry:\n",
    "\t\tresponse = requests.get(url)\n",
    "\t\timage_content = response.content\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error - could not download {url} - {e}\")\n",
    "\t\treturn None\n",
    "\ttry:\n",
    "\t\timage_file = io.BytesIO(image_content)\n",
    "\t\timage = Image.open(image_file).convert('RGB')\n",
    "\t\tfile_name = hashlib.sha1(image_content).hexdigest()[:10] + '.jpg'\n",
    "\t\tfile_path = os.path.join(os.path.abspath(output_path), file_name)\n",
    "\t\tif os.path.isfile(file_path):\n",
    "\t\t\tif verbose: print(f\"File already exists in the output directory: {file_path}\")\n",
    "\t\telse: \n",
    "\t\t\twith open(file_path, 'wb') as writeFile:\n",
    "\t\t\t\timage.save(writeFile, \"JPEG\", quality=85)\n",
    "\t\t\tif verbose : print(f\"image downloaded succesfully {url} - as file {file_path}\")\n",
    "\t\treturn file_name\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error : could not process downloaded image content\\n--> {url} - {e}\")\n",
    "\t\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download images from urls and saving them in output directory\n",
    "def fetch_images_from_urls(urls, output_dir, urls_tsv_path, verbose=False):\n",
    "\turl_2_file_name = {}\n",
    "\tprint('Starting to download images from fetched urls...')\n",
    "\tcount = 0\n",
    "\told_urls = set()\n",
    "\tif os.path.isfile(urls_tsv_path):\n",
    "\t\twith open(urls_tsv_path, 'r') as readFile:\n",
    "\t\t\tfor line in readFile:\n",
    "\t\t\t\told_urls.add(line.rstrip().split('\\t')[1])\n",
    "\tfor url in urls:\n",
    "\t\tcount += 1\n",
    "\t\tif url in old_urls:\n",
    "\t\t\tprint('Image with the current url is already downloaded last time')\n",
    "\t\t\tcontinue\n",
    "\t\tfile_name = download_image(url, output_dir, verbose)\n",
    "\t\tif file_name is not None:\n",
    "\t\t\turl_2_file_name[url] = file_name\n",
    "\t\tif count % 50 == 0:\n",
    "\t\t\tprint(f'Total images downloaded from Google Images : {count}/{len(urls)}')\n",
    "\tprint(\"Downloading complete.... generated Url2FileName Dictionary ... :)\")\n",
    "\treturn url_2_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing urls in an tsv file, [just a precautionary measure(not anymore I think)] later help in data manipulation\n",
    "def writeURLS(url_2_file_name, urls_path):\n",
    "\tprint('Starting updating URL - FILE NAME tsv file...')\n",
    "\turl_2_file_name_buffer = {}\n",
    "\tif os.path.isfile(urls_path):\n",
    "\t\twith open(urls_path, 'r') as readFile:\n",
    "\t\t\tfor line in readFile:\n",
    "\t\t\t\t# print(line)\n",
    "\t\t\t\tfile_name, url = line.rstrip().split('\\t')\n",
    "\t\t\t\turl_2_file_name_buffer[url] = file_name\n",
    "\tfor url in url_2_file_name:\n",
    "\t\turl_2_file_name_buffer[url] = url_2_file_name[url]\n",
    "\twith open(urls_path, 'w') as writeFile:\n",
    "\t\tfor url in url_2_file_name_buffer:\n",
    "\t\t\twriteFile.write(url_2_file_name_buffer[url] + '\\t' + url + '\\n')\n",
    "\tprint(f'Updating urls finished with the file path : {os.path.abspath(urls_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(N, Query, Output_Directory, url=None, wt=0.3, tsv_path='./scrapped_images_urls_names.tsv', verbose=True):\n",
    "\t# browser= webdriver.Chrome(<PATH FOR THE CHROME DRIVER>)\n",
    "\tif not os.path.isdir(Output_Directory):\n",
    "\t\tos.mkdir(Output_Directory)\n",
    "\tbrowser= webdriver.Chrome('./chromedriver')\n",
    "\turls = extractImagesURLS(Query, url, N, wt, browser, verbose)\n",
    "\turl_2_file_name = fetch_images_from_urls(urls, Output_Directory, tsv_path)\n",
    "\twriteURLS(url_2_file_name, tsv_path)\n",
    "\tprint('Finished... :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = 'Empty Fridge'\n",
    "Verbose = True\n",
    "Output_Directory = './output'\n",
    "URL = None\n",
    "Wait_Time = 1\n",
    "URL_TSV_PATH = './scrapped_images_urls_names.tsv'\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 100 search results. Extracting links from 0 : 100\n",
      "checking for the limit of the number of images to be downloaded: 10\n",
      "Found: 10 image links\n",
      "Starting to download images from fetched urls...\n",
      "Error : could not process downloaded image content\n",
      "--> https://wildtalesof.com/wp-content/uploads/2019/04/empty-fridge-1024x768.jpg - cannot identify image file <_io.BytesIO object at 0x7f8398adfdb0>\n",
      "Downloading complete.... generated Url2FileName Dictionary ... :)\n",
      "Starting updating URL - FILE NAME tsv file...\n",
      "Updating urls finished with the file path : /home/solus/scrapped_images_urls_names.tsv\n",
      "Finished... :)\n"
     ]
    }
   ],
   "source": [
    "main(N, Query, Output_Directory, url=URL, wt=Wait_Time, tsv_path=URL_TSV_PATH, verbose=Verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
